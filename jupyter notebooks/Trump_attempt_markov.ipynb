{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import nltk\n",
    "import spacy\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/ancav/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Markov chains\n",
    "- calculate the probability of transitioning from one word to another based on unique words in a corpus (text speeches Trump in our case)\n",
    "- once all the probabilities are fed, we can feed it a word from the corpus until we tell it to stop\n",
    "- in order for the sentences to be gramatically correct or sensical, we should not use the \"memoryless\" property: the only context for a word is based on a list of previous words\n",
    "- if the sequences on which we base the state are longer, we overfit the data\n",
    "- add back-off which tells the generator to start with a sequence of x words and check if the size of the bag of possivle next words to that sequence is larger than a value y; if the requirement isn't met, the model falls back on a shorter sentence consisting of the last x-1 words form the original sentence\n",
    "\n",
    "CAVEAT - not all the generated text will make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Markov(object):\n",
    "    def __init__(self, corpus, n_grams, min_length):\n",
    "        \"\"\"\n",
    "        corpus = list of string text\n",
    "        n_grams = max sequence length\n",
    "        min_length = minimum number of next words required for back-off to the markov text generator \"\"\"\n",
    "\n",
    "        self.grams = {}\n",
    "        self.n_grams = n_grams\n",
    "        self.corpus = corpus\n",
    "        self.min_length = min_length\n",
    "        self.sequences()\n",
    "    \n",
    "    def tokenize_text(self, text, gram):\n",
    "        \"\"\"tokenize the speeches in the corpus and split them on the number of grams desired\"\"\"\n",
    "        \n",
    "        tokenized_speech = nltk.word_tokenize(text)\n",
    "        \n",
    "        if len(tokenized_speech) < gram:\n",
    "            pass\n",
    "        else:\n",
    "            for i in range(len(tokenized_speech) - gram):\n",
    "                yield (tokenized_speech[i:i + (gram +1)])\n",
    "                \n",
    "    def sequences(self):\n",
    "        \"\"\"create all the sequences of length up to n_grams\"\"\"\n",
    "        \n",
    "        for gram in range(1, self.n_grams + 1):\n",
    "            dictionary = {}\n",
    "            for speech in self.corpus:\n",
    "                for sequence in self.tokenize_text(speech, gram):\n",
    "                    key_id = tuple(sequence[0:-1])\n",
    "                    \n",
    "                    # check if the key is in the dictionary\n",
    "                    if key_id in dictionary.keys():\n",
    "                        dictionary[key_id].append(sequence[gram])\n",
    "                    else:\n",
    "                        dictionary[key_id] = [sequence[gram]]\n",
    "            self.grams[gram] = dictionary\n",
    "            \n",
    "    def next_word(self, key_id):\n",
    "        \"\"\"return the next word for an input sequence but back off to shorter sequence if length requirement\n",
    "        is not met\"\"\"\n",
    "        for i in range(len(key_id)):\n",
    "            try:\n",
    "                if len(self.grams[len(key_id)][key_id]) >= self.min_length:\n",
    "                    return random.choice(self.grams[len(key_id)][key_id])\n",
    "            except KeyError:\n",
    "                pass\n",
    "            \n",
    "        # shrink the key_id if the requirement is not met\n",
    "        if len(key_id)>1:\n",
    "            key_id == key_id[1:]\n",
    "            \n",
    "        try:\n",
    "            return random.choice(self.grams[len(key_id)][key_id])\n",
    "        except KeyError:\n",
    "            # key does not exist, choose next word at random\n",
    "            return random.choice(\" \".join(self.corpus).split())\n",
    "    \n",
    "    def next_key(self, key_id, res):\n",
    "        return tuple(key_id[1:]) + tuple([res])\n",
    "    \n",
    "    def generate_text(self, start, size = 6):\n",
    "        \"\"\"the start is a group of words of at least n_grams words\"\"\"\n",
    "        key_id = tuple(nltk.word_tokenize(start))[-self.n_grams:]\n",
    "        gen_words = []\n",
    "        i = 0\n",
    "        while i <= size:\n",
    "            result = self.next_word(key_id)\n",
    "            key_id = self.next_key(key_id, result)\n",
    "            gen_words.append(result)\n",
    "            i+=1\n",
    "        print(start + \" \" + \" \".join(gen_words).replace(\" .\", \".\").replace(\" ,\", \",\"))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"trump_speech_hillary.txt\", \"r\")\n",
    "f = file.read()\n",
    "corpus = f.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hillary Clinton President in to rules capabilities the now time was who in\n"
     ]
    }
   ],
   "source": [
    "mark = Markov(corpus, 2, 2)\n",
    "mark.generate_text(\"Hillary Clinton\", size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import markovify\n",
    "from time import time\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run time for training the generator : 0.05 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time()\n",
    "com_generator = markovify.Text(corpus, state_size = 2)\n",
    "print(\"Run time for training the generator : {} seconds\".format(round(time()-start_time, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print randomly-generated comments using the built model\n",
    "def generate_comments(generator, number=10, short=False):\n",
    "    count = 0\n",
    "    while count < number:\n",
    "        if short:\n",
    "            comment = generator.make_short_sentence(90)\n",
    "        else:\n",
    "            comment = generator.make_sentence()\n",
    "        if comment:\n",
    "            count += 1\n",
    "            print(\"Comment {}\".format(count))\n",
    "            print(comment)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-f9a063a58dbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenerate_comments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcom_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-3c5da8d2ed6c>\u001b[0m in \u001b[0;36mgenerate_comments\u001b[0;34m(generator, number, short)\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0mcomment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_short_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mcomment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcomment\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/markovify/text.py\u001b[0m in \u001b[0;36mmake_sentence\u001b[0;34m(self, init_state, **kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtest_output\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rejoined_text\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_sentence_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_join\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/markovify/text.py\u001b[0m in \u001b[0;36mtest_sentence_output\u001b[0;34m(self, words, max_overlap_ratio, max_overlap_total)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mgram_joined\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_join\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mgram_joined\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrejoined_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "generate_comments(com_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class POSifiedText(markovify.Text):\n",
    "    def word_split(self, sentence):\n",
    "        return [\"::\".join((word.orth_, word.pos_)) for word in nlp(sentence)]\n",
    "\n",
    "    def word_join(self, words):\n",
    "        sentence = \" \".join(word.split(\"::\")[0] for word in words)\n",
    "        return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time()\n",
    "comments_generator_POSified = POSifiedText(tweets, state_size = 2)\n",
    "print(\"Run time for training the generator : {} seconds\".format(round(time()-start_time, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
